{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chebyshev polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is method to estimate the exponential of a matrix based on a polynomial approximation exponential function for an argument $|x|<1$. The idea is that, given a function $f(\\omega)$ which is defined in the complex domain $\\omega \\in[-i,i]$, it can be very well approximated using the Chebyshev polynomials\n",
    "\\begin{eqnarray}\n",
    "T_0 &=&1,\\\\\n",
    "T_1 &=&x,\\\\\n",
    "T_n &=& 2x T_k(x) - T_{k-1}(x)\n",
    "\\end{eqnarray}\n",
    "using the orthonormal expansion\n",
    "$$f(\\omega) = \\sum_k a_k T_k(\\omega),$$\n",
    "where $a_k$ are the projection of the function on that domain with a particular measure\n",
    "$$a_k = -i\\int_{-i}^i (1-|\\omega|^2)^{-1/2}f(\\omega) T_k(\\omega)\\mathrm{d}\\omega.$$\n",
    "We use this expansion to approximate the evolution operator\n",
    "$$\\exp(-i \\Delta t H) = e^{-i r_+}\\exp(r_- B),$$\n",
    "where $r_\\pm = \\Delta t(\\lambda_{max}\\pm\\lambda_{min})/2$ is built from the maximum and minimum eigenvalues $\\lambda_{max}$ and $\\lambda_{min}$ of $H$, to construct an operator\n",
    "$$B = \\frac{-i}{r_-}(\\Delta t H - r_+),$$\n",
    "whose spectrum lays in $[-i,i]$. Using this, we have\n",
    "$$\\exp(-i \\Delta t H) = e^{-ir_+}\\left[J_0(r_-) + 2\\sum_k J_k(r_-)T_k(B)\\right],$$\n",
    "where $J_k(x)$ are the Bessel functions of the first kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: seeq/chebyshev.py\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse.linalg\n",
    "from scipy.special import jn\n",
    "import scipy.linalg as la\n",
    "import scipy.sparse.linalg as sla\n",
    "import warnings\n",
    "\n",
    "class AccuracyWarning(Warning):\n",
    "    pass\n",
    "\n",
    "class ChebyshevExpm:\n",
    "    \"\"\"\n",
    "    This object is created to compute $exp(-i*H*dt)*v$ using\n",
    "    the Chebyshev series to approximate the exponential. The\n",
    "    object does some preconditioning or scaling of the operator\n",
    "    based on the range of eigenvalues and 'factor', transforming\n",
    "    it to $exp(-i*A*R)*v$ where B has eigenvalues in [-1,1] and\n",
    "    R is a real number.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    H         -- A matrix or a LinearOperator() with shape (d,d)\n",
    "    d         -- matrix size, only needs to be provided when H is a function\n",
    "    bandwidth -- An upper bound on the spectral bandwidth of A\n",
    "    \"\"\"\n",
    "    def __init__(self, H, d=None, bandwidth=None):\n",
    "        #\n",
    "        # H can be a function, a matrix, a sparse matrix, etc. We construct\n",
    "        # a linear operator in all cases, which is a general abstraction that\n",
    "        # numpy can work with and allows multiplication times a vector '@'\n",
    "        #\n",
    "        # The method demands that the eigenvalues be in the range [-1,1]\n",
    "        # We need analyze the operator to estimate a range of eigenvalues\n",
    "        # and rescale the operator \"A*factor\" to a smaller range.\n",
    "        #\n",
    "        if callable(H) and not isinstance(H, sla.LinearOperator):\n",
    "            H = scipy.sparse.linalg.LinearOperator((d,d),matvec=H)\n",
    "        self.H = H\n",
    "        #\n",
    "        # Estimate the spectral range of H, computing the smallest and\n",
    "        # largest eigenvalues. ARPACK in standard Python is not good at\n",
    "        # computing small values. We thus use a trick of computing the\n",
    "        # largest magnitude X and assume the spectrum is in [-X,X]\n",
    "        #\n",
    "        if bandwidth is None:\n",
    "            λmax = sla.eigs(H, k=1, which='LM', return_eigenvectors=0)[0]\n",
    "            Hnorm = abs(λmax)\n",
    "            bandwidth = 2*Hnorm\n",
    "        if np.isscalar(bandwidth):\n",
    "            self.height = bandwidth/2.0\n",
    "            self.center = 0.0\n",
    "        else:\n",
    "            Emin, Emax = bandwidth\n",
    "            self.height = 0.5 * (Emax - Emin)\n",
    "            self.center = 0.5 * (Emax + Emin)\n",
    "\n",
    "    @staticmethod\n",
    "    def weights(order, rm):\n",
    "        ndx = np.arange(0,order)\n",
    "        return jn(ndx, rm) * ((-1j)**ndx)\n",
    "                    \n",
    "    def apply(self, v, order=100, dt=1.0, tol=1e-14):\n",
    "        \"\"\"Apply the Chebyshev approximation of the exponential exp(1i*dt*A)\n",
    "        onto the vector or matrix `v`.        \n",
    "        Parameters\n",
    "        ----------\n",
    "        v     -- A vector or a matrix\n",
    "        order -- the order of the Chebyshev approximation\n",
    "        dt    -- time interval in the exponential above\n",
    "        tol   -- relative tolerance for deciding when to stop the\n",
    "                 Chebyshev expansion\n",
    "        \"\"\"\n",
    "        rp = dt * self.center\n",
    "        rm = dt * self.height\n",
    "        order = max(order, 2 * int(rm))\n",
    "        \n",
    "        # Apply a version of A that is shifted and rescaled \n",
    "        def Btimes(phi):\n",
    "            #\n",
    "            # There's something stupid about LinearOperators that always return\n",
    "            # matrices when applied to arrays. This screws our use of vdot()\n",
    "            # and other operations below\n",
    "            return np.asarray((self.H @ phi) * (dt/rm) - phi * (rp/rm))\n",
    "    \n",
    "        # Bessel coefficients ak, plus imaginary parts from chebyshev polynomials    \n",
    "        ak = self.weights(order, rm)\n",
    "    \n",
    "        # Zeroth and first order\n",
    "        phi0 = v\n",
    "        phi1 = Btimes(phi0)\n",
    "        cheb = ak[0] * phi0 + 2 * ak[1] * phi1\n",
    "    \n",
    "        # We can define an absolute tolerance if we assume unitary evolution\n",
    "        # and always a nonzero relative tolerance 'tol'\n",
    "        # Note the 'vector' 'v' is actually a matrix of vectors with columns\n",
    "        # corresponding to different states. We want to compute the total\n",
    "        # norm of the vectors in a speedy way.\n",
    "        atol2 = np.abs(tol**2 * np.vdot(v, v))\n",
    "        \n",
    "        # Higher orders\n",
    "        for jj in range(2,order):\n",
    "            phi2 = 2 * Btimes(phi1) - phi0\n",
    "            tmp = 2 * ak[jj] * phi2\n",
    "            cheb += tmp\n",
    "            if abs(np.vdot(tmp,tmp)) < atol2:\n",
    "                break\n",
    "            phi0 = phi1\n",
    "            phi1 = phi2\n",
    "        else:\n",
    "            warnings.warn(f'Desired precision {tol} not reached with {order} steps. '\n",
    "                          f'Error is {np.linalg.norm(tmp)/np.linalg.norm(cheb)}',\n",
    "                          AccuracyWarning)\n",
    "\n",
    "        return cheb * np.exp(-1j*rp)\n",
    "    \n",
    "def expm(A, v, d=None, bandwidth=None, **kwargs):\n",
    "    \"\"\"Apply the Chebyshev approximation of the exponential exp(1i*dt*A)\n",
    "    onto the vector or matrix `v`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A         -- A matrix or a LinearOperator() with shape (d,d), or\n",
    "                 a linear function that acts on vectors.\n",
    "    v         -- A vector or a matrix with shapes (d,) or (d,M)\n",
    "    d         -- Dimension of matrix A. Only required when A is\n",
    "                 a function or callable object\n",
    "    bandwidth -- An upper bound on the spectral bandwidth of A or\n",
    "                 a pair (Emin, Emax) of extreme eigenvalues\n",
    "    order     -- the order of the Chebyshev approximation\n",
    "    dt        -- time interval in the exponential above\n",
    "    tol       -- relative tolerance for deciding when to stop the\n",
    "                 Chebyshev expansion\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    newv      -- A vector or a matrix approximating expm(1j*dt*A) @ v\n",
    "    \"\"\"\n",
    "    aux = ChebyshevExpm(A, d=d, bandwidth=bandwidth)\n",
    "    return aux.apply(v, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebyshevExpm = expm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Krylov methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to compute a  function $f(A)$ of some linear operator $A$, acting on a vector $v_0$. Krylov methods building an approximation to $f(A)*v_0$ in the Krylov space of vectors given by\n",
    "$$K = \\text{lin}\\{ v, A v, A^2 v, \\ldots \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This space of vectors can be constructed from an orthogonal set of vectors\n",
    "$$v_n \\propto A v_{n-1} - \\sum_{m\\leq n} (v_{m}^\\dagger A v_{n-1}) v_{m}$$\n",
    "where $v_1=v$ is the initial vector mentioned above and\n",
    "$$K = \\text{lin}\\{v_1,v_2\\ldots\\}$$\n",
    "There are two alternative approaches, depending on whether our operator is Hermitian or not. We follow the work by Y. Saad [(SIAM J. Numer. Anala. 29(1), 209-228.)](https://doi.org/10.1137/0729014) for the definition of the algorithms and the error analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krylov exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If A is not Hermitian, we need construct an orthonormal basis of vectors, $V_m = [v_1,v_2,\\ldots,v_m]$ to describe the Krylov subspace $K_m$ where we will implement the approximation of the exponential. The basis is constructed recursively, with the following algorithm\n",
    "\n",
    "1. Initialize. Compute $v_1=v/\\Vert{v}\\Vert_2$\n",
    "2. Iterate. Do $j=1,2,\\ldots,m$\n",
    "   1. Compute $w := A v_j$\n",
    "   2. Do $i=1,2,\\ldots,j$\n",
    "       1. Compute $h_{i,j} = (w, v_i)$\n",
    "       2. Compute $w := w - h_{ij} v_i$\n",
    "   3. Compute $h_{j+1,j} := \\Vert{w}\\Vert_2, \\; v_{j+1}:=w/h_{j+1,j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Via this process, we are computing a Hessemberg matrix $(H_m)_{ij}=h_{ij}$ with the relation\n",
    "$$A V_m = V_m H_m + h_{m+1,m} v_{m+1} e^T_m,$$\n",
    "where $e_m$ is the unit vector where only the $m-$th component is nonzero.\n",
    "In other words, $H_m$ is an almost exact representation of $A$ in the new basis and the second term is the error. This also allows to approximate\n",
    "$$e^{\\tau A} v \\simeq \\Vert{v}\\Vert_2 V_m e^{\\tau H_m} e_1.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to know how many vectors we need to compute so as to make the error $\\varepsilon_m$ small enough. There exist various a-priori estimates that depend on the spectral radius of $A$, the factor $\\tau$ and the order of approximation $m$. When $A$ is skew-symmetric, a good upper bound is\n",
    "$$\\varepsilon_m \\leq 12 e^{-(\\rho\\tau)^2/m}\\left(\\frac{e\\rho\\tau}{m}\\right)^m < \\frac{\\Vert A\\Vert^m}{m!}$$\n",
    "provided $m > 2\\rho\\tau$. Another upper bound is\n",
    "$$\\varepsilon_m < \\frac{\\Vert A\\Vert^m}{m!},\\quad m > \\Vert A\\Vert$$\n",
    "Neither of them is too tight, but it could serve us to guess a good starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our algorithm below, we do not rely so much on a-priori bounds. Instead we use a guess for the order of approximation and then verify it with an a-posteriori bound. This later bound uses the information on the exponential of the matrix $H$, as well as the latest $\\beta$ that has been computed\n",
    "$$\\Vert\\varepsilon_m\\Vert \\leq \\Vert{v}\\Vert_2 h_{m+1,m} |e^T_m e^{H_m} e_1|$$\n",
    "We use this bound to repeatedly increase the number of vectors until convergence. Note, however, that there is a limit in the precission imposed by the numerical errors in the computer. This has to be taken in to account to stop the recursion when we hit that wall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: seeq/lanczos.py\n",
    "\n",
    "import numpy\n",
    "import scipy\n",
    "import scipy.linalg as la\n",
    "import scipy.sparse.linalg as sla\n",
    "import warnings\n",
    "\n",
    "class AccuracyWarning(Warning):\n",
    "    pass\n",
    "\n",
    "class ArnoldiExpm:\n",
    "    def __init__(self, H, d=0):\n",
    "        #\n",
    "        # H can be a function, a matrix, a sparse matrix, etc. We construct\n",
    "        # a linear operator in all cases, which is a general abstraction that\n",
    "        # numpy can work with and allows multiplication times a vector '@'\n",
    "        #\n",
    "        if callable(H) and not isinstance(H, sla.LinearOperator):\n",
    "            H = sla.LinearOperator((d,d),matvec=H)\n",
    "        self.H = H            \n",
    "    \n",
    "    def estimateOrder(self, dt=1.0):\n",
    "        #\n",
    "        # Estimate the order of the Lanczos expansion\n",
    "        #\n",
    "        self.Hnorm = abs(sla.eigs(self.H, k=1, which='LM', return_eigenvectors=0)[0])\n",
    "        return max(int(3*self.Hnorm*dt+1),4)\n",
    "\n",
    "    def apply(self, v, dt=1.0, order=None, tol=1e-14):\n",
    "        # This function has two ways to operate: if we provide an order,\n",
    "        # it applies the Lanczos expansion up to that basis size; otherwise\n",
    "        # it estimates the number of vectors based on the norm of the matrix\n",
    "        # that we will exponentiate (which was estimated before in __init__)\n",
    "        nmax = 12 if order is None else order\n",
    "        #\n",
    "        # Construct a projected version of the matrix 'H' on the\n",
    "        # Krylov subspace generated around vector 'v'\n",
    "        #\n",
    "        v = numpy.asarray(v)\n",
    "        β = numpy.linalg.norm(v)\n",
    "        vn = v / β\n",
    "        V = []\n",
    "        H = scipy.sparse.dok_matrix((v.size,v.size))\n",
    "        lasterr = 1.0\n",
    "        start = 0\n",
    "        while True:\n",
    "            for j in range(start,nmax):\n",
    "                V.append(vn)\n",
    "                w = numpy.asarray(self.H @ vn)\n",
    "                for i in range(j):\n",
    "                    H[i,j] = hij = numpy.vdot(w, V[i])\n",
    "                    w -= hij * V[i]\n",
    "                H[j+1,j] = hlast = numpy.linalg.norm(w)\n",
    "                if hlast < 1e-20:\n",
    "                    break\n",
    "                vn = w / hlast\n",
    "            #\n",
    "            # We diagonalize the banded matrix formed by α and β and\n",
    "            # use that to compute the exponential of the effective\n",
    "            # truncated matrix. This also allows us to estimate the error\n",
    "            # due to the Lanczos method.\n",
    "            #\n",
    "            Hj = H.copy()\n",
    "            Hj.resize((j+1,j+1))\n",
    "            e1 = np.zeros(j+1)\n",
    "            e1[0] = 1.0\n",
    "            y = scipy.sparse.linalg.expm_multiply((-1j*dt)*Hj.tocsr(), e1)\n",
    "            err = abs(hlast * y[-1])\n",
    "            if err < tol:\n",
    "                break\n",
    "            if lasterr < err or nmax == v.size or (order is not None):\n",
    "                warnings.warn(f'Arnoldi failed to converge at {j+1} iterations with error {err}',\n",
    "                              AccuracyWarning)\n",
    "                lasterr = err\n",
    "                break\n",
    "            start = nmax\n",
    "            nmax = min(int(1.5*nmax+1), v.size)\n",
    "        #\n",
    "        # Given the approximation of the exponential, recompute the\n",
    "        # Lanczos basis \n",
    "        #\n",
    "        return np.array(V).T @ (β * y)\n",
    "    \n",
    "def expm(A, v, **kwargs):\n",
    "    aux = LanczosExpm(A, d=v.size)\n",
    "    return aux.apply(v, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arnoldiExpm = expm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lanczos exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If A is Hermitian, two things happen. The first one is that the projection of $A$ onto the basis $\\{v_n\\}$ is very simple\n",
    "$$H_{mm}:=(v_{m}^\\dagger A v_{n})={\\begin{pmatrix}\\alpha _{1}&\\beta _{2}&&&&0\\\\\\beta _{2}&\\alpha _{2}&\\beta _{3}&&&\\\\&\\beta _{3}&\\alpha _{3}&\\ddots &&\\\\&&\\ddots &\\ddots &\\beta _{m-1}&\\\\&&&\\beta _{m-1}&\\alpha _{m-1}&\\beta _{m}\\\\0&&&&\\beta _{m}&\\alpha _{m}\\\\\\end{pmatrix}}$$\n",
    "The second one is that the iterative construction of the orthonormal basis is very simple and involves only one product of matrix times a vector, and two additions\n",
    "$$v_{n+1} = \\frac{1}{\\beta_{n+1}}(A v_n - \\alpha_n v_n - \\beta_n v_{n-1})$$\n",
    "$$\\alpha_n = (v_n^\\dagger A v_n)$$\n",
    "$$\\beta_n = (v_{n-1}^\\dagger A v_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our algorithm below, we do not rely so much on a-priori bounds. Instead we use a guess for the order of approximation and then verify it with an a-posteriori bound. This later bound uses the information on the exponential of the matrix $T$, as well as the latest $\\beta$ that has been computed\n",
    "$$\\Vert\\varepsilon_m\\Vert \\leq \\left[exp(-\\tau H)\\right]_{m,1}\\times |\\beta_{m}|$$\n",
    "We use this bound to repeatedly increase the number of vectors until convergence. Note, however, that there is a limit in the precission imposed by the numerical errors in the computer. This has to be taken in to account to stop the recursion when we hit that wall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: seeq/lanczos.py\n",
    "\n",
    "import numpy\n",
    "import scipy\n",
    "import scipy.linalg as la\n",
    "import scipy.sparse.linalg as sla\n",
    "import warnings\n",
    "\n",
    "class AccuracyWarning(Warning):\n",
    "    pass\n",
    "\n",
    "class LanczosExpm:\n",
    "    def __init__(self, H, d=0):\n",
    "        #\n",
    "        # H can be a function, a matrix, a sparse matrix, etc. We construct\n",
    "        # a linear operator in all cases, which is a general abstraction that\n",
    "        # numpy can work with and allows multiplication times a vector '@'\n",
    "        #\n",
    "        if callable(H) and not isinstance(H, sla.LinearOperator):\n",
    "            H = sla.LinearOperator((d,d),matvec=H)\n",
    "        self.H = H\n",
    "\n",
    "    def apply(self, v, dt=1.0, order=None, tol=1e-14):\n",
    "        # This function has two ways to operate: if we provide an order,\n",
    "        # it applies the Lanczos expansion up to that basis size; otherwise\n",
    "        # it estimates the number of vectors based on the norm of the matrix\n",
    "        # that we will exponentiate (which was estimated before in __init__)\n",
    "        nmax = 10 if order is None else order\n",
    "        if nmax > v.size:\n",
    "            nmax = v.size\n",
    "        #\n",
    "        # Construct a projected version of the matrix 'H' on the\n",
    "        # Krylov subspace generated around vector 'v'\n",
    "        #\n",
    "        v = numpy.array(v)\n",
    "        vnrm = la.norm(v)\n",
    "        vn = v / vnrm\n",
    "        vnm1 = numpy.zeros(v.shape)\n",
    "        α = []\n",
    "        β = [0.0]\n",
    "        start = 0\n",
    "        lasterr = vnrm * 1e10\n",
    "        while True:\n",
    "            #\n",
    "            # Iteratively extend the Krylov basis using the lanczos\n",
    "            # recursion without restart or reorthogonalization.\n",
    "            #\n",
    "            for n in range(start, nmax):\n",
    "                w = numpy.asarray(self.H @ vn)\n",
    "                α.append(numpy.vdot(vn, w))\n",
    "                w = w - α[n] * vn - β[n] * vnm1\n",
    "                vnm1 = vn\n",
    "                aux = la.norm(w)\n",
    "                β.append(aux)\n",
    "                if aux < 1e-20:\n",
    "                    break\n",
    "                vn = w / aux\n",
    "            #\n",
    "            # We diagonalize the banded matrix formed by α and β and\n",
    "            # use that to compute the exponential of the effective\n",
    "            # truncated matrix. This also allows us to estimate the error\n",
    "            # due to the Lanczos method.\n",
    "            #\n",
    "            w, u = scipy.linalg.eig_banded(numpy.array([β[:-1],α]),\n",
    "                                           overwrite_a_band=True)\n",
    "            fHt = u @ (numpy.exp(-1j*dt*w) * u[0,:].conj())\n",
    "            err = abs(fHt[n]*β[n+1])\n",
    "            if err < tol:\n",
    "                break\n",
    "            if lasterr < err or nmax == v.size or (order is not None):\n",
    "                warnings.warn(f'Lanczos failed to converge at {len(α)} iterations with error {err}',\n",
    "                              AccuracyWarning)\n",
    "                lasterr = err\n",
    "                break\n",
    "            start = nmax\n",
    "            nmax = min(int(1.5*nmax+1), v.size)\n",
    "        #\n",
    "        # Given the approximation of the exponential, recompute the\n",
    "        # Lanczos basis \n",
    "        #\n",
    "        vnm1 = vn = v\n",
    "        output = fHt[0] * vn\n",
    "        for n in range(1, nmax):\n",
    "            w = numpy.asarray(self.H @ vn) - α[n-1] * vn - β[n-1] * vnm1\n",
    "            vnm1 = vn\n",
    "            vn = w / β[n]\n",
    "            output = output + fHt[n] * vn\n",
    "        return output\n",
    "    \n",
    "def expm(A, v, **kwargs):\n",
    "    aux = LanczosExpm(A, d=v.size)\n",
    "    return aux.apply(v, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanczosExpm = expm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse.linalg as sla\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def chebyTest1(size, **kw):\n",
    "    factor = 1.0\n",
    "    if ('factor' in kw):\n",
    "        factor = kw['factor']\n",
    "    #\n",
    "    # Create a random Hermitian matrix and a vector\n",
    "    #\n",
    "    A = np.random.randn(size,size)\n",
    "    A = np.dot(A, A.T)\n",
    "    v = np.random.randn(size)\n",
    "    v = v / la.norm(v)\n",
    "    #\n",
    "    # Numerically exact exponential\n",
    "    #\n",
    "    w1 = la.expm(-1j * A * factor) @ v\n",
    "    #\n",
    "    # Set of orders that we wish to test\n",
    "    #\n",
    "    them = [m for m in range(3,size,4)]\n",
    "    #\n",
    "    # Estimate operator norm\n",
    "    #\n",
    "    Anrm = abs(sla.eigs(A, k=1, which='LM', return_eigenvectors=0)[0]*factor)\n",
    "    #\n",
    "    # Error estimates for Lanczos\n",
    "    #\n",
    "    rho = Anrm/4.0\n",
    "    est = [abs(12*math.exp(m-rho*rho/m)*(rho/m)**m) for m in them]\n",
    "    #\n",
    "    # Error estimates for Lanczos (2nd, bit worse)\n",
    "    #\n",
    "    rho = Anrm/4.0\n",
    "    est2 = [abs(2*math.exp(m*math.log(Anrm/2)-math.lgamma(m))) for m in them]\n",
    "    #\n",
    "    # Actual Lanczos errors\n",
    "    #\n",
    "    aux = LanczosExpm(A)\n",
    "    err1 = [la.norm(w1 - aux.apply(v,order=m,dt=factor)) for m in them]\n",
    "    #\n",
    "    # Selfregulated Lanczos errors\n",
    "    #\n",
    "    aux = LanczosExpm(A)\n",
    "    err1b = [la.norm(w1 - aux.apply(v,dt=factor))\n",
    "             for m in them]\n",
    "    #\n",
    "    # Selfregulated Arnoldi errors\n",
    "    #\n",
    "    aux = ArnoldiExpm(A)\n",
    "    err1c = [la.norm(w1 - aux.apply(v,dt=factor))\n",
    "             for m in them]\n",
    "    #\n",
    "    # Chebyshev class errors\n",
    "    #\n",
    "    err3 = [la.norm(w1 - chebyshevExpm(A,v,dt=factor,order=m)) for m in them]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(them, est, '--', label='Norm bound')\n",
    "    ax.plot(them, est2, '--', label='Norm bound2')\n",
    "    ax.plot(them, err1, '-', label='Lanczos fixed order')\n",
    "    ax.plot(them, err1b, '-', label='Lanczos expm')\n",
    "    ax.plot(them, err1c, '-', label='Arnoldi expm')\n",
    "    ax.plot(them, err3, '.-', label='Chebyshev expm')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Lanczos No. vectors')\n",
    "    ax.set_ylabel('Exponential error')\n",
    "    ax.legend()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"default\", category=AccuracyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = chebyTest1(50, factor=1/1000.0)\n",
    "ax.set_ylim([1e-16,1e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = chebyTest1(40, factor=1/500.0)\n",
    "ax.set_ylim([1e-16,1e-2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse.linalg as sla\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def lanczosTiming(size, chebyshev_order=100, factor=1.0, iterations=100):\n",
    "    #\n",
    "    # Create a random Hermitian matrix and a vector\n",
    "    #\n",
    "    A = np.random.randn(size,size)\n",
    "    A = np.dot(A, A.T)\n",
    "    v = np.random.randn(size)\n",
    "    v = v / la.norm(v)\n",
    "    #\n",
    "    aux = LanczosExpm(A)\n",
    "    t = time.process_time()\n",
    "    for i in range(0,iterations):\n",
    "        aux.apply(v,dt=factor)\n",
    "    t = (time.process_time() - t)/iterations\n",
    "    print('LanczosExpm t=',t,'s / iteration')\n",
    "    #\n",
    "    aux = ArnoldiExpm(A)\n",
    "    t = time.process_time()\n",
    "    for i in range(0,iterations):\n",
    "        aux.apply(v,dt=factor)\n",
    "    t = (time.process_time() - t)/iterations\n",
    "    print('Arnoldi t=',t,'s / iteration')\n",
    "    #\n",
    "    aux = ChebyshevExpm(A)\n",
    "    t = time.process_time()\n",
    "    for i in range(0,iterations):\n",
    "        aux.apply(v,dt=factor,order=chebyshev_order)\n",
    "    t = (time.process_time() - t)/iterations\n",
    "    print('Chebyshev t=',t,'s / iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanczosTiming(300, chebyshev_order=60, factor=1/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanczosTiming(300, chebyshev_order=90, factor=1/500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
