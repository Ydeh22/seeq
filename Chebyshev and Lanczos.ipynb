{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chebyshev polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is method to estimate the exponential of a matrix based on a polynomial approximation exponential function for an argument $|x|<1$. The idea is that, given a function $f(\\omega)$ which is defined in the complex domain $\\omega \\in[-i,i]$, it can be very well approximated using the Chebyshev polynomials\n",
    "\\begin{eqnarray}\n",
    "T_0 &=&1,\\\\\n",
    "T_1 &=&x,\\\\\n",
    "T_n &=& 2x T_k(x) - T_{k-1}(x)\n",
    "\\end{eqnarray}\n",
    "using the orthonormal expansion\n",
    "$$f(\\omega) = \\sum_k a_k T_k(\\omega),$$\n",
    "where $a_k$ are the projection of the function on that domain with a particular measure\n",
    "$$a_k = -i\\int_{-i}^i (1-|\\omega|^2)^{-1/2}f(\\omega) T_k(\\omega)\\mathrm{d}\\omega.$$\n",
    "We use this expansion to approximate the evolution operator\n",
    "$$\\exp(-i \\Delta t H) = e^{-i r_+}\\exp(r_- A),$$\n",
    "where $r_\\pm = \\Delta t(\\lambda_{max}\\pm\\lambda_{min})/2$ is built from the maximum and minimum eigenvalues $\\lambda_{max}$ and $\\lambda_{min}$ of $H$, to construct an operator\n",
    "$$B = \\frac{-i}{r_-}(\\Delta t H - r_+),$$\n",
    "whose spectrum lays in $[-i,i]$. Using this, we have\n",
    "$$\\exp(-i \\Delta t H) = e^{-ir_+}\\left[J_0(r_-) + 2\\sum_k J_k(r_-)T_k(B)\\right],$$\n",
    "where $J_k(x)$ are the Bessel functions of the first kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: seeq/chebyshev.py\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse.linalg\n",
    "from scipy.special import jn\n",
    "import scipy.linalg as la\n",
    "import scipy.sparse.linalg as sla\n",
    "\n",
    "class ChebyshevExpm:\n",
    "    \"\"\"\n",
    "    This object is created to compute $exp(-i*H*dt)*v$ using\n",
    "    the Chebyshev series to approximate the exponential. The\n",
    "    object does some preconditioning or scaling of the operator\n",
    "    based on the range of eigenvalues and 'factor', transforming\n",
    "    it to $exp(-i*A*R)*v$ where B has eigenvalues in [-1,1] and\n",
    "    R is a real number.\n",
    "    \n",
    "    H     -- a matrix, or a linear function f(v) on vectors\n",
    "    d     -- matrix size, only needs to be provided when H is a function\n",
    "    order -- the order of the Chebyshev approximation\n",
    "    dt    -- time interval in the exponential above\n",
    "    rtol  -- relative tolerance for deciding when to stop the\n",
    "             Chebyshev expansion\n",
    "    \"\"\"\n",
    "    def __init__(self, H, d=None, largestEig=0):\n",
    "        #\n",
    "        # H can be a function, a matrix, a sparse matrix, etc. We construct\n",
    "        # a linear operator in all cases, which is a general abstraction that\n",
    "        # numpy can work with and allows multiplication times a vector '@'\n",
    "        #\n",
    "        # The method demands that the eigenvalues be in the range [-1,1]\n",
    "        # We need analyze the operator to estimate a range of eigenvalues\n",
    "        # and rescale the operator \"A*factor\" to a smaller range.\n",
    "        #\n",
    "        if callable(H) and not isinstance(H, sla.LinearOperator):\n",
    "            H = scipy.sparse.linalg.LinearOperator((d,d),matvec=H)\n",
    "        self.H = H\n",
    "        #\n",
    "        # Estimate the spectral range of H, computing the smallest and\n",
    "        # largest eigenvalues. ARPACK in standard Python is not good at\n",
    "        # computing small values. We thus use a trick of computing the\n",
    "        # largest magnitude X and assume the spectrum is in [-X,X]\n",
    "        #\n",
    "        if largestEig:\n",
    "            self.largestEig = largestEig\n",
    "            self.smallestEig = -largestEig\n",
    "        else:\n",
    "            self.Hnorm = abs(sla.eigsh(H, k=1, which='LM', return_eigenvectors=0)[0])\n",
    "            self.largestEig = self.Hnorm\n",
    "            self.smallestEig = - self.Hnorm\n",
    "    \n",
    "    @staticmethod\n",
    "    def weights(order, rm):\n",
    "        ndx = np.arange(0,order)\n",
    "        return jn(ndx, rm) * ((-1j)**ndx)\n",
    "                    \n",
    "    def apply(self, v, order=100, dt=1.0, tol=1e-14):\n",
    "        \n",
    "        rp = dt * (self.largestEig + self.smallestEig) / 2\n",
    "        rm = dt * (self.largestEig - self.smallestEig) / 2\n",
    "        order = max(order, 2 * int(rm))\n",
    "        \n",
    "        # Apply a version of A that is shifted and rescaled \n",
    "        def Btimes(phi):\n",
    "            return ((self.H @ phi) * (dt/rm) - phi * (rp/rm))\n",
    "    \n",
    "        # Bessel coefficients ak, plus imaginary parts from chebyshev polynomials    \n",
    "        ak = self.weights(order, rm)\n",
    "    \n",
    "        # Zeroth and first order\n",
    "        phi0 = v\n",
    "        phi1 = Btimes(phi0)\n",
    "        cheb = ak[0] * phi0 + 2 * ak[1] * phi1\n",
    "    \n",
    "        # We can define an absolute tolerance if we assume unitary evolution\n",
    "        # and always a nonzero relative tolerance 'tol'\n",
    "        # Note the 'vector' 'v' is actually a matrix of vectors with columns\n",
    "        # corresponding to different states. We want to compute the total\n",
    "        # norm of the vectors in a speedy way.\n",
    "        atol2 = np.abs(tol**2 * np.vdot(v, v))\n",
    "        \n",
    "        # Higher orders\n",
    "        for jj in range(2,order):\n",
    "            phi2 = 2 * Btimes(phi1) - phi0\n",
    "            tmp = 2 * ak[jj] * phi2\n",
    "            cheb += tmp\n",
    "            if abs(np.vdot(tmp,tmp)) < atol2:\n",
    "                break\n",
    "            phi0 = phi1\n",
    "            phi1 = phi2\n",
    "        else:\n",
    "            print(\"Desired precision of \", tol, \"not reached.\")\n",
    "            print(\"Error = \", np.linalg.norm(tmp)/np.linalg.norm(cheb))\n",
    "\n",
    "        return cheb * np.exp(-1j*rp)\n",
    "    \n",
    "def expm(A, v, **kwargs):\n",
    "    aux = ChebyshevExpm(A)\n",
    "    return aux.apply(v, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebyshevExpm = expm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lanczos exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we design and test a version of the exponential that works using the Krylov basis without reorthogonalization, taking as input any object that acts as a matrix or linear operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to compute a  function $f(A)$ of some linear operator $A$, acting on a vector $v_0$. The method to implement this is based on building an approximation to $f(A)*v_0$ in the Krylov space of vectors given by\n",
    "$$K = \\text{lin}\\{ v, A v, A^2 v, \\ldots \\}$$\n",
    "Fortunately, this space of vectors can be constructed from an orthogonal set of vectors\n",
    "$$v_n \\propto A v_{n-1} - \\sum_{m\\leq n} (v_{m}^\\dagger A v_{n-1}) v_{m}$$\n",
    "where $v_1=v$ is the initial vector mentioned above and\n",
    "$$K = \\text{lin}\\{v_1,v_2\\ldots\\}$$\n",
    "Fortunately for us, two things happen. The first one is that the projection of $A$ onto the basis $\\{v_n\\}$ is very simple\n",
    "$$T_{mm}:=(v_{m}^\\dagger A v_{n})={\\begin{pmatrix}\\alpha _{1}&\\beta _{2}&&&&0\\\\\\beta _{2}&\\alpha _{2}&\\beta _{3}&&&\\\\&\\beta _{3}&\\alpha _{3}&\\ddots &&\\\\&&\\ddots &\\ddots &\\beta _{m-1}&\\\\&&&\\beta _{m-1}&\\alpha _{m-1}&\\beta _{m}\\\\0&&&&\\beta _{m}&\\alpha _{m}\\\\\\end{pmatrix}}$$\n",
    "The second one is that the iterative construction of the orthonormal basis is very simple and involves only one product of matrix times a vector, and two additions\n",
    "$$v_{n+1} = \\frac{1}{\\beta_{n+1}}(A v_n - \\alpha_n v_n - \\beta_n v_{n-1})$$\n",
    "$$\\alpha_n = (v_n^\\dagger A v_n)$$\n",
    "$$\\beta_n = (v_{n-1}^\\dagger A v_n)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this allows us to define approximations to the exponential that are usually written in the form\n",
    "$$\\exp(-\\tau A) v \\simeq V_m \\exp(-\\tau T) e_1 + \\varepsilon_m$$\n",
    "where $V_m$ is the matrix that has as columns the $\\{v_i\\}_{i=1}^m$ vectors, $e_1$ is the vector which is only one in the first element and the error $\\varepsilon_m$ depends on the spectral radius of $A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to know how many vectors we need to compute so as to make the error $\\varepsilon_m$ small enough. There exist various a-priori estimates that depend on the spectral radius of $A$, the factor $\\tau$ and the order of approximation $m$. When $A$ is skew-symmetric, a good upper bound is\n",
    "$$\\varepsilon_m \\leq 12 e^{-(\\rho\\tau)^2/m}\\left(\\frac{e\\rho\\tau}{m}\\right)^m < \\frac{\\Vert A\\Vert^m}{m!}$$\n",
    "provided $m > 2\\rho\\tau$. Another upper bound is\n",
    "$$\\varepsilon_m < \\frac{\\Vert A\\Vert^m}{m!},\\quad m > \\Vert A\\Vert$$\n",
    "Neither of them is too tight, but it could serve us to guess a good starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our algorithm below, we do not rely so much on a-priori bounds. Instead we use a guess for the order of approximation and then verify it with an a-posteriori bound. This later bound uses the information on the exponential of the matrix $T$, as well as the latest $\\beta$ that has been computed\n",
    "$$\\Vert\\varepsilon_m\\Vert \\leq \\left[exp(-\\tau T)\\right]_{m,1}\\times |\\beta_{m}|$$\n",
    "We use this bound to repeatedly increase the number of vectors until convergence. Note, however, that there is a limit in the precission imposed by the numerical errors in the computer. This has to be taken in to account to stop the recursion when we hit that wall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: seeq/lanczos.py\n",
    "\n",
    "import numpy\n",
    "import scipy\n",
    "import scipy.linalg as la\n",
    "import scipy.sparse.linalg as sla\n",
    "\n",
    "class LanczosExpm:\n",
    "    def __init__(self, H, d=0):\n",
    "        #\n",
    "        # H can be a function, a matrix, a sparse matrix, etc. We construct\n",
    "        # a linear operator in all cases, which is a general abstraction that\n",
    "        # numpy can work with and allows multiplication times a vector '@'\n",
    "        #\n",
    "        if callable(H) and not isinstance(H, sla.LinearOperator):\n",
    "            H = sla.LinearOperator((d,d),matvec=H)\n",
    "        self.H = H\n",
    "        #\n",
    "        # Estimate the spectral range of H, computing the smallest and\n",
    "        # largest eigenvalues. ARPACK in standard Python is not good at\n",
    "        # computing small values. We thus use a trick of computing the\n",
    "        # largest magnitude X and assume the spectrum is in [-X,X]\n",
    "        #\n",
    "        self.Hnorm = abs(sla.eigs(H, k=1, which='LM', return_eigenvectors=0)[0])\n",
    "    \n",
    "    def estimateOrder(self, dt=1.0):\n",
    "        return max(int(3*self.Hnorm*dt+1),4)\n",
    "\n",
    "    def apply(self, v, dt=1.0, order=0, tol=1e-14):\n",
    "        # This function has two ways to operate: if we provide an order,\n",
    "        # it applies the Lanczos expansion up to that basis size; otherwise\n",
    "        # it estimates the number of vectors based on the norm of the matrix\n",
    "        # that we will exponentiate (which was estimated before in __init__)\n",
    "        if order == 0:\n",
    "            nmax = self.estimateOrder(dt)\n",
    "        else:\n",
    "            nmax = order\n",
    "        if nmax > v.size:\n",
    "            nmax = v.size\n",
    "        #\n",
    "        # Construct a projected version of the matrix 'H' on the\n",
    "        # Krylov subspace generated around vector 'v'\n",
    "        #\n",
    "        v = numpy.array(v)\n",
    "        vnrm = la.norm(v)\n",
    "        vn = v / vnrm\n",
    "        vnm1 = numpy.zeros(v.shape)\n",
    "        α = []\n",
    "        β = [0.0]\n",
    "        start = 0\n",
    "        lasterr = 1.0\n",
    "        while True:\n",
    "            #\n",
    "            # Iteratively extend the Krylov basis using the lanczos\n",
    "            # recursion without restart or reorthogonalization.\n",
    "            #\n",
    "            for n in range(start, nmax):\n",
    "                w = (self.H @ vn)\n",
    "                α.append(numpy.vdot(vn, w))\n",
    "                w = w - α[n] * vn - β[n] * vnm1\n",
    "                vnm1 = vn\n",
    "                aux = la.norm(w)\n",
    "                β.append(aux)\n",
    "                if aux < 1e-20:\n",
    "                    break\n",
    "                vn = w / aux\n",
    "            #\n",
    "            # We diagonalize the banded matrix formed by α and β and\n",
    "            # use that to compute the exponential of the effective\n",
    "            # truncated matrix. This also allows us to estimate the error\n",
    "            # due to the Lanczos method.\n",
    "            #\n",
    "            w, u = scipy.linalg.eig_banded(numpy.array([β[:-1],α]),\n",
    "                                           overwrite_a_band=True)\n",
    "            fHt = u @ (numpy.exp(-1j*dt*w) * u[0,:].conj())\n",
    "            err = abs(fHt[n]*β[n+1])\n",
    "            if err < tol:\n",
    "                break\n",
    "            if lasterr < err or nmax == v.size:\n",
    "                print('Lanczos failed to converge at ', len(α), ' iterations')\n",
    "                print('err='+str(err))\n",
    "                lasterr = err\n",
    "                break\n",
    "            start = nmax\n",
    "            nmax = min(int(1.5*nmax+1), v.size)\n",
    "        #\n",
    "        # Given the approximation of the exponential, recompute the\n",
    "        # Lanczos basis \n",
    "        #\n",
    "        vnm1 = vn = v\n",
    "        output = fHt[0] * vn\n",
    "        for n in range(1, nmax):\n",
    "            w = (self.H @ vn) - α[n-1] * vn - β[n-1] * vnm1\n",
    "            vnm1 = vn\n",
    "            vn = w / β[n]\n",
    "            output = output + fHt[n] * vn\n",
    "        return output\n",
    "    \n",
    "def expm(A, v, **kwargs):\n",
    "    aux = LanczosExpm(A, d=v.size)\n",
    "    return aux.apply(v, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanczosExpm = expm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse.linalg as sla\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def chebyTest1(size, **kw):\n",
    "    factor = 1.0\n",
    "    if ('factor' in kw):\n",
    "        factor = kw['factor']\n",
    "    #\n",
    "    # Create a random Hermitian matrix and a vector\n",
    "    #\n",
    "    A = np.random.rand(size,size)\n",
    "    A = np.dot(A, A.T)\n",
    "    v = np.random.rand(size)\n",
    "    v = v / la.norm(v)\n",
    "    #\n",
    "    # Numerically exact exponential\n",
    "    #\n",
    "    w1 = la.expm(-1j * A * factor) @ v\n",
    "    #\n",
    "    # Set of orders that we wish to test\n",
    "    #\n",
    "    them = [m for m in range(3,size,4)]\n",
    "    #\n",
    "    # Estimate operator norm\n",
    "    #\n",
    "    Anrm = abs(sla.eigs(A, k=1, which='LM', return_eigenvectors=0)[0]*factor)\n",
    "    mmin = Anrm\n",
    "    #\n",
    "    # Error estimates for Lanczos\n",
    "    #\n",
    "    rho = Anrm/4.0\n",
    "    est = [abs(12*math.exp(m-rho*rho/m)*(rho/m)**m) for m in them]\n",
    "    #\n",
    "    # Error estimates for Lanczos (2nd, bit worse)\n",
    "    #\n",
    "    rho = Anrm/4.0\n",
    "    est2 = [abs(2*math.exp(m*math.log(Anrm/2)-math.lgamma(m))) for m in them]\n",
    "    #\n",
    "    # Actual Lanczos errors\n",
    "    #\n",
    "    aux = LanczosExpm(A)\n",
    "    err1 = [la.norm(w1 - aux.apply(v,order=m,dt=factor)) for m in them]\n",
    "    #\n",
    "    # Selfregulated Lanczos errors\n",
    "    #\n",
    "    aux = LanczosExpm(A)\n",
    "    err1b = [la.norm(w1 - aux.apply(v,dt=factor))\n",
    "             for m in them]\n",
    "    #\n",
    "    # Chebyshev class errors\n",
    "    #\n",
    "    err3 = [la.norm(w1 - chebyshevExpm(A,v,dt=factor,order=m)) for m in them]\n",
    "    ax = plt.gca()\n",
    "    ax.plot(them,est,'--',them,est2,'--',\n",
    "            them,err1,'-',them,err1b,'-',them,err3,'-.',\n",
    "            [mmin,mmin],[1e-16,10],'--.')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xlabel('Lanczos No. vectors')\n",
    "    ax.set_ylabel('Exponential error');\n",
    "    ax.legend(['Lanczos bound','Lanczos bound2',\n",
    "               'Lanczos fixed order','LanczosExpm','ChebyshevExpm',\n",
    "              'OrderEstimate']);\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = chebyTest1(300, factor=1/1000.0)\n",
    "ax.set_ylim([1e-16,10])\n",
    "ax.set_xlim([0,80]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = chebyTest1(300, factor=1/500.0)\n",
    "ax.set_ylim([1e-16,10])\n",
    "ax.set_xlim([0,110]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse.linalg as sla\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def lanczosTiming(size, chebyshev_order=100, factor=1.0, iterations=100):\n",
    "    #\n",
    "    # Create a random Hermitian matrix and a vector\n",
    "    #\n",
    "    A = np.random.rand(size,size)\n",
    "    A = np.dot(A, A.T)\n",
    "    v = np.random.rand(size)\n",
    "    v = v / la.norm(v)\n",
    "    #\n",
    "    aux = LanczosExpm(A)\n",
    "    t = time.process_time()\n",
    "    for i in range(0,iterations):\n",
    "        aux.apply(v,dt=factor)\n",
    "    t = (time.process_time() - t)/iterations\n",
    "    print('LanczosExpm t=',t,'s / iteration')\n",
    "    #\n",
    "    aux = ChebyshevExpm(A)\n",
    "    t = time.process_time()\n",
    "    for i in range(0,iterations):\n",
    "        aux.apply(v,dt=factor,order=chebyshev_order)\n",
    "    t = (time.process_time() - t)/iterations\n",
    "    print('Chebyshev t=',t,'s / iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanczosTiming(300, chebyshev_order=60, factor=1/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lanczosTiming(300, chebyshev_order=90, factor=1/500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
